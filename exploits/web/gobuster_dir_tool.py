import uuid
from typing import Type, Any
from urllib.parse import urljoin

from crewai_tools import BaseTool
from pydantic.v1 import BaseModel, Field
from sqlalchemy import exc
from datetime import datetime

from helpers import fingers
from helpers.crawler import crawl_host
from helpers.gobuster import Gobuster
from config import logger
from persistence.database import DB
from persistence.orm import DuplicateException, UrlEnum


class GobusterDirToolSchema(BaseModel):
    """GobusterDirToolSchema 的查询参数"""
    url: str = Field(..., description="host或url地址, 一个host或者完整的url地址")


class GobusterDirTool(BaseTool):
    name: str = "Gobuster"
    description: str = "url路径枚举工具，用于发现隐藏或未公开的url路径"
    args_schema: Type[BaseModel] = GobusterDirToolSchema
    db: DB | None = None
    task_id: int | None = None
    webinfo_id: int | None = None
    gobuster_path: str | None = None
    wordlist_path: str | None = None

    class Config:
        arbitrary_types_allowed = True

    def __init__(self, db: DB, task_id: int, webinfo_id: int, gobuster_path: str = None, wordlist_path: str = None):
        super().__init__()
        self.db = db
        self.task_id = task_id
        self.webinfo_id = webinfo_id
        self.gobuster_path = gobuster_path
        self.wordlist_path = wordlist_path
        logger.info("初始化工具 Gobuster")

    def _run(
            self,
            **kwargs: Any,
    ) -> Any:
        url = kwargs.pop('url', "")
        if url == "":
            return "url为空"

        try:
            logger.info("Gobuster: {}", url)
            gobuster = Gobuster(wordlist=self.wordlist_path, gobusterAbsPath=self.gobuster_path)
            result = gobuster.dir(url)
            # 添加一个随机path
            result.append(str(uuid.uuid4()))
            if len(result) == 0:
                return "未找到任何结果"

            now = datetime.now()
            with self.db.DBSession() as session:
                for r in result:
                    htmls = crawl_host(urljoin(url, r))
                    if len(htmls) == 0:
                        continue
                    for html in htmls:
                        matched = fingers.Match(html.headers, html.body, [i.mmh3hash for i in html.favicons],
                                                [i.md5hash for i in html.favicons])
                        urlenumdb = UrlEnum()
                        urlenumdb.task_id = self.task_id
                        urlenumdb.web_info_id = self.webinfo_id
                        urlenumdb.host = html.host
                        urlenumdb.schema = html.schema
                        urlenumdb.url = html.url
                        urlenumdb.path = r
                        urlenumdb.current_redirects = html.current_redirects
                        urlenumdb.redirect_to = html.redirect_to
                        urlenumdb.title = html.title
                        urlenumdb.status = html.status
                        urlenumdb.headers = html.headers
                        urlenumdb.favicons = [favicon.to_dict() for favicon in html.favicons]
                        urlenumdb.body = html.body
                        urlenumdb.created = now
                        urlenumdb.finger_prints = [match.to_dict() for match in matched]
                        urlenumdb.source = self.name
                        try:
                            session.add(urlenumdb)
                            session.commit()
                        except DuplicateException as e:
                            session.rollback()
                        except Exception as e:
                            raise

            return f"共发现{len(result)}个目录"
        except exc.SQLAlchemyError as e:
            logger.error("数据库错误: {}", e)
            return "数据库错误"
        except Exception as e:
            logger.error("获取失败: {}", e)
            return f"获取失败: {e}"
